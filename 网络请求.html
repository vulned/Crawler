<!DOCTYPE html>
<html>
<head>
<title>网络请求</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
</head>
<body>
<h1>网络请求</h1>
<h2>1.urllib库   ---内置</h2>
<h3>urlopen函数：</h3>
<p>创建一个表示远程url的类文件对象，然后像本地文件一样操作这个类文件对象来获取远程数据。</p>
<p>url：请求的url。
data：请求的data，如果设置了这个值，那么将变成post请求。
返回值：返回值是一个http.client.HTTPResponse对象，这个对象是一个类文件句柄对象。有read(size)、readline、readlines以及getcode等方法。</p>
<h3>urlretrieve函数：</h3>
<p>这个函数可以方便的将网页上的一个文件保存到本地。</p>
<p><code>python
request.urlretrieve(url,文件名)</code></p>
<h3>urlencode函数：编码</h3>
<p>urlencode可以把字典数据转换为URL编码的数据。</p>
<p>```python
from urllib import parse</p>
<p>data = {'name':'老王','age':18,'greet':'hello world'}</p>
<p>qs = parse.urlencode(data)
print(qs)</p>
<h1>name=%E8%80%81%E7%8E%8B&amp;age=18&amp;greet=hello+world</h1>
<p>```</p>
<h3>parse_qs函数：解码</h3>
<p>可以将经过编码后的url参数进行解码</p>
<p>```python
print(parse.parse_qs(qs))</p>
<h1>{'name': ['老王'], 'age': ['18'], 'greet': ['hello world']}</h1>
<p>```</p>
<h3>urlparse和urlsplit函数：解析url</h3>
<p>```python
from urllib import parse</p>
<p>url = 'http://www.baidu.com/index.html;user?id=S#comment'</p>
<p>result = parse.urlparse(url)</p>
<h1>result = parse.urlsplit(url)</h1>
<p>print(result)
print(result.scheme)
print(result.netloc)
print(result.path)</p>
<h1>urlparse里有params属性，而urlsplit没有这个params属性。</h1>
<p>print(result.params)
```</p>
<h3>request.Request类：网络请求  可以增加请求头</h3>
<p>```python
from urllib import request</p>
<p>headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 			(KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'
}</p>
<p>rq = request.Request('https://www.baidu.com/',headers=headers)</p>
<p>resp = request.urlopen(rq)</p>
<p>print(resp.read())
```</p>
<h3>ProxyHandler处理器（代理设置）：封ip问题</h3>
<ol>
<li>
<p>代理原理：在请求目的网站之前，先请求代理服务器，然后让代理服务器去请求目的网站，代理服务器拿到目的网站的数据后，再转发给我们的代码。</p>
</li>
<li>
<p>http://httpbin.org：这个网站可以方便的查看http请求的一些参数。</p>
</li>
<li>
<p>在代码中使用代理  示例：</p>
</li>
</ol>
<p><code>python
   # 使用代理
   # 步骤
   url = 'http://httpbin.org/ip'
   #1. 使用ProxyHandler,传入代理构建一个handler
   handler = request.ProxyHandler({'http':'122.193.244.243:9999'})
   #2. 使用上面创建的handler构建一个opener
   opener = request.build_opener(handler)
   #3. 使用opener去发送一个请求
   resp = opener.open(url)
   print(resp.read())</code></p>
<h3>cookie:           登录</h3>
<ol>
<li>
<p>什么是cookie：指某些网站为了辨别用户身份、进行 session 跟踪而储存在用户本地终端上的数据</p>
</li>
<li>
<p>cookie的格式：
   Set-Cookie: NAME=VALUE；Expires/Max-age=DATE；Path=PATH；         Domain=DOMAIN_NAME；SECURE
   参数意义：
   NAME：cookie的名字。
   VALUE：cookie的值。
   Expires：cookie的过期时间。
   Path：cookie作用的路径。
   Domain：cookie作用的域名。
   SECURE：是否只在https协议下起作用。</p>
</li>
</ol>
<h3>http.cookiejar模块：提供用于存储cookie的对象</h3>
<ol>
<li>CookieJar：管理HTTP cookie值、存储HTTP请求生成的cookie、向传出的HTTP请求添加cookie的对象。整个cookie都存储在内存中，对CookieJar实例进行垃圾回收后cookie也将丢失。</li>
<li>
<p>FileCookieJar (filename,delayload=None,policy=None)：从CookieJar派生而来，用来创建FileCookieJar实例，检索cookie信息并将cookie存储到文件中。filename是存储cookie的文件名。delayload为True时支持延迟访问访问文件，即只有在需要时才读取文件或在文件中存储数据。</p>
</li>
<li>
<p>MozillaCookieJar (filename,delayload=None,policy=None)：从FileCookieJar派生而来，创建与Mozilla浏览器 cookies.txt兼容的FileCookieJar实例。</p>
</li>
<li>
<p>LWPCookieJar (filename,delayload=None,policy=None)：从FileCookieJar派生而来，创建与libwww-perl标准的 Set-Cookie3 文件格式兼容的FileCookieJar实例。</p>
</li>
</ol>
<p>实例：</p>
<p>```python
from urllib import request
from urllib import parse
from http.cookiejar import  CookieJar</p>
<h1>登录：https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fwww.meishij.net%2F</h1>
<h1>个人网页https://i.meishi.cc/cook.php?id=13686422</h1>
<p>headers={
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'
}</p>
<h1>1.登录</h1>
<h1>1.1 创建cookiejar对象</h1>
<p>cookiejar = CookieJar()</p>
<h1>1.2 使用cookiejar创建一个HTTPCookieProcess对象</h1>
<p>handler = request.HTTPCookieProcessor(cookiejar)</p>
<h1>1.3 使用上一步的创建的handler创建一个opener</h1>
<p>opener = request.build_opener(handler)</p>
<h1>1.4 使用opener发送登录请求  (账号和密码)</h1>
<p>post<em>url = 'https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fwww.meishij.net%2F'
post</em>data = parse.urlencode({
    'username':'1097566154@qq.com',
    'password':'wq15290884759.'
})
req = request.Request(post<em>url,data=post</em>data.encode('utf-8'))
opener.open(req)</p>
<h1>2.访问个人网页</h1>
<p>url = 'https://i.meishi.cc/cook.php?id=13686422'
rq = request.Request(url,headers=headers)
resp = opener.open(rq)
print(resp.read().decode('utf-8'))
```</p>
<p>cookie加载与保存</p>
<p>```python
from urllib import request
from http.cookiejar import MozillaCookieJar</p>
<h1>保存</h1>
<h1>cookiejar = MozillaCookieJar('cookie.txt')</h1>
<h1>handler = request.HTTPCookieProcessor(cookiejar)</h1>
<h1>opener = request.build_opener(handler)</h1>
<h1>resp = opener.open('http://www.httpbin.org/cookies/set/course/abc')</h1>
<h1></h1>
<h1>cookiejar.save(ignore<em>discard=True,ignore</em>expires=True)</h1>
<h1>ignore_discard=True  即使cookies即将被丢弃也要保存下来</h1>
<h1>ignore_expires=True  如果cookies已经过期也将它保存并且文件已存在时将覆盖</h1>
<h1>加载</h1>
<p>cookiejar = MozillaCookieJar('cookie.txt')
cookiejar.load()
handler = request.HTTPCookieProcessor(cookiejar)
opener = request.build_opener(handler)
resp = opener.open('http://www.httpbin.org/cookies/set/course/abc')</p>
<p>for cookie in cookiejar:
    print(cookie)
```</p>
<h2>2.requests库   ---第三方库</h2>
<p>Requests：让HTTP服务人类</p>
<h3>安装和文档地址：</h3>
<p><code>pip install requests</code></p>
<h3>发送GET请求</h3>
<p>```python
import requests</p>
<h1>添加headers和查询参数</h1>
<p>headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'
}
kw = {'wd':'中国'}</p>
<h1>params 接收一个字典或者字符串的查询参数，字典类型自动转换为url编码，不需要urlencode()</h1>
<p>response = requests.get('https://www.baidu.com/s',headers=headers,params=kw)
print(response)</p>
<h1>属性</h1>
<h1>查询响应内容</h1>
<p>print(response.text)  #返回unicode格式的数据
print(response.content) #返回字节流数据
print(response.url)  #查看完整url地址
print(response.encoding) # 查看响应头部字符编码
```</p>
<h4>response.text和response.content的区别：</h4>
<ol>
<li><code>response.content</code> ：这个是直接从网络上抓取的数据，没有经过任何的编码，所以是一个bytes类型，其实在硬盘上和网络上传输的字符串都是bytes类型</li>
<li><code>response.text</code>：这个是str的数据类型，是requests库将response.content进行解码的字符串，解码需要指定一个编码方式，requests会根据自己的猜测来判断编码的方式，所以有时候可能会猜测错误，就会导致解码产生乱码，这时候就应该进行手动解码，比如使用<code>response.content.decode('utf-8')</code></li>
</ol>
<h3>发送POST请求：</h3>
<p><code>python
response = requests.post(&quot;http://www.baidu.com/&quot;,data=data)</code></p>
<p>POST请求方式</p>
<p>```python
import requests</p>
<p>url = 'https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fwww.meishij.net%2F'
headers={
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'
}
data = {
    'redirect': 'https://www.meishij.net/',
    'username': '1097566154@qq.com',
    'password': 'wq15290884759.'
}
resp = requests.post(url,headers=headers,data=data)
print(resp.text)
```</p>
<h3>使用代理：</h3>
<p>只要在请求的方法中（比如get或者post）传递proxies参数就可以了。</p>
<p>```python
import requests</p>
<p>proxy = {
    'http':'111.77.197.127:9999'
}
url = 'http://www.httpbin.org/ip'
resp = requests.get(url,proxies=proxy)
print(resp.text)
```</p>
<h3>cookie：</h3>
<p>基本使用：模拟登陆</p>
<p><code>python
import requests
url = 'https://www.zhihu.com/hot'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36',
    'cookie':'_zap=59cde9c3-c5c0-4baa-b756-fa16b5e72b10; d_c0=&quot;APDi1NJcuQ6PTvP9qa1EKY6nlhVHc_zYWGM=|1545737641&quot;; __gads=ID=237616e597ec37ad:T=1546339385:S=ALNI_Mbo2JturZesh38v7GzEeKjlADtQ5Q; _xsrf=pOd30ApWQ2jihUIfq94gn2UXxc0zEeay; q_c1=1767e338c3ab416692e624763646fc07|1554209209000|1545743740000; tst=h; __utma=51854390.247721793.1554359436.1554359436.1554359436.1; __utmc=51854390; __utmz=51854390.1554359436.1.1.utmcsr=zhihu.com|utmccn=(referral)|utmcmd=referral|utmcct=/hot; __utmv=51854390.100-1|2=registration_date=20180515=1^3=entry_date=20180515=1; l_n_c=1; l_cap_id=&quot;OWRiYjI0NzJhYzYwNDM3MmE2ZmIxMGIzYmQwYzgzN2I=|1554365239|875ac141458a2ebc478680d99b9219c461947071&quot;; r_cap_id=&quot;MmZmNDFkYmIyM2YwNDAxZmJhNWU1NmFjOGRkNDNjYjc=|1554365239|54372ab1797cba8c4dd224ba1845dd7d3f851802&quot;; cap_id=&quot;YzQwNGFlYWNmNjY3NDFhNGI4MGMyYjZjYjRhMzQ1ZmE=|1554365239|385cc25e3c4e3b0b68ad5747f623cf3ad2955c9f&quot;; n_c=1; capsion_ticket=&quot;2|1:0|10:1554366287|14:capsion_ticket|44:MmE5YzNkYjgzODAyNDgzNzg5MTdjNmE3NjQyODllOGE=|40d3498bedab1b7ba1a247d9fc70dc0e4f9a4f394d095b0992a4c85e32fd29be&quot;; z_c0=&quot;2|1:0|10:1554366318|4:z_c0|92:Mi4xOWpCeUNRQUFBQUFBOE9MVTBseTVEaVlBQUFCZ0FsVk5iZzJUWFFEWi1JMkxnQXlVUXh2SlhYb3NmWks3d1VwMXRB|81b45e01da4bc235c2e7e535d580a8cc07679b50dac9e02de2711e66c65460c6&quot;; tgw_l7_route=578107ff0d4b4f191be329db6089ff48'
}
resp = requests.get(url,headers=headers)
print(resp.text)</code></p>
<h4>session：共享cookie</h4>
<p>案例：</p>
<p>```python
post_url = 'https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fwww.meishij.net%2F'</p>
<p>post_data = {
    'username':'1097566154@qq.com',
    'password':'wq15290884759.'
}
headers={
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'
}</p>
<h1>登录</h1>
<p>session = requests.session()
session.post(post<em>url,headers=headers,data=post</em>data)</p>
<h1>访问个人网页</h1>
<p>url = 'https://i.meishi.cc/cook.php?id=13686422'</p>
<p>resp = session.get(url)
print(resp.text)
```</p>
<h3>处理不信任的SSL证书：</h3>
<p>对于那些已经被信任的SSL证书的网站，比如https://www.baidu.com/，那么使用requests直接就可以正常的返回响应。示例代码如下：</p>
<p><code>python
resp = requests.get('https://inv-veri.chinatax.gov.cn/',verify=False)
print(resp.content.decode('utf-8'))</code></p>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
